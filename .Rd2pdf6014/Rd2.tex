\nonstopmode{}
\documentclass[a4paper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\makeatletter\@ifl@t@r\fmtversion{2018/04/01}{}{\usepackage[utf8]{inputenc}}\makeatother
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `SpecLatent'}}
\par\bigskip{\large \today}
\end{center}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdftitle = {SpecLatent: Spectral Methods for Latent Variable Models}}}{}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdfauthor = {Ling Chen; Yuqi Gu; Zhongyuan Lyu; Chengzhu Huang; Seunghyun Lee}}}{}
\begin{description}
\raggedright{}
\item[Type]\AsIs{Package}
\item[Title]\AsIs{Spectral Methods for Latent Variable Models}
\item[Version]\AsIs{0.0.1.0}
\item[Description]\AsIs{This package contains spectral methods for latent variable models, including the generlized-GoM model and degree-heterogeneous latent class model.}
\item[Encoding]\AsIs{UTF-8}
\item[RoxygenNote]\AsIs{7.3.1}
\item[BugReports]\AsIs{}\url{https://github.com/lscientific/SpecLatent/issues}\AsIs{}
\item[Depends]\AsIs{R (>= 2.10)}
\item[Imports]\AsIs{RSpectra, RcppHungarian}
\item[Suggests]\AsIs{ggplot2}
\item[LazyData]\AsIs{true}
\end{description}
\Rdcontents{Contents}
\HeaderA{DhLCM}{DhLCM}{DhLCM}
%
\begin{Description}
This function performs k-means clustering on the top \code{K} eigenvectors/left singular vectors, and estimates the DhLCM model parameters
\end{Description}
%
\begin{Usage}
\begin{verbatim}
DhLCM(
  R,
  K,
  spectral = "heteroPCA",
  norm = "L2",
  dist = "Bern",
  T0 = 20,
  nstart = 10,
  S0 = NULL,
  clustering_only = F
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{R}] Numeric matrix. Data matrix.

\item[\code{K}] Positive integer. The number of top eigenvectors/left singular vectors to be extracted.

\item[\code{spectral}] Numeric matrix or character. One of data matrix, \code{"heteroPCA"} and \code{"SVD"}. 
If is a matrix, it is treated as U. Otherwise needs to be a string that 
specifies the method to be used to obtain the top \code{K} 
eigenvectors/left singular vectors. 
\code{"heteroPCA"} implements the heteroPCA method. 
\code{"SVD"} performs ordinary singular vector decomposition.

\item[\code{norm}] Character or \code{NULL}. One of \code{"L2"}, \code{"L1"}, \code{"SCORE"}, and \code{NULL}. 
Specifies the method to be used for normalization on the eigenvectors/left singular vectors. 
\code{"L2"} performs L2 normalization. 
\code{"L1"} performs L1 normalization.
\code{"SCORE"} performs SCORE normalization.
\code{"NA"} does not perform normalization.

\item[\code{dist}] Character. One of \code{"Bern"}, \code{"Binom"}, and \code{"Pois"}. Specifies the data distribution.
\code{"Bern"} assumes the Bernoulli distribution.
\code{"Binom"} assumes the Binomial distribution.
\code{"Pois"} assumes the Poisson distribution.

\item[\code{T0}] Positive integer. The number of iterations for heteroPCA. Only used when spectral is \code{'heteroPCA'}

\item[\code{nstart}] Positive integer. The number of initial starts in the kmeans function.

\item[\code{S0}] Vector or \code{NULL}. If is not \code{NULL}, used to permute the labels.

\item[\code{clustering\_only}] Boolean. When \code{true}, only clustering is conducted.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Named list. The list is made of:
\begin{itemize}

\item{} \code{U} --- Numeric matrix. Estimation of the left singular matrix.
\item{} \code{T\_hat} --- Numeric matrix. Estimation of the \eqn{\Theta}{} matrix.
\item{} \code{sigma2\_hat} --- Numeric vector (>=0). Asymptotic variance for each element of \code{T\_hat}.
\item{} \code{S\_hat} --- Numeric vector. Clustered membership for each subject.
\item{} \code{Z\_hat} --- Numeric matrix. Clustered membership for each subject in binary matrix form.

\end{itemize}

\end{Value}
%
\begin{References}
Lyu, Zhongyuan, Ling Chen, and Yuqi Gu. "Degree-heterogeneous Latent Class Analysis for High-dimensional Discrete Data." arXiv preprint arXiv:2402.18745 (2024).
\end{References}
\HeaderA{diag\_deletion}{diag\_deletion}{diag.Rul.deletion}
%
\begin{Description}
This function takes in a matrix, and returns the diagonal-deleted matrix
\end{Description}
%
\begin{Usage}
\begin{verbatim}
diag_deletion(X)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{X}] Numeric matrix
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A matrix of with diagonals set to 0
\end{Value}
\HeaderA{flatten}{flatten}{flatten}
%
\begin{Description}
Flatten the polytomous matrix to a fat binary matrix
\end{Description}
%
\begin{Usage}
\begin{verbatim}
flatten(R)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{R}] integer matrix. The polytomous response data matrix.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
\begin{description}

\item[\code{R\_flattened}    flattened binary matrix.] 
\end{description}

\end{Value}
\HeaderA{gGoM}{gGoM}{gGoM}
%
\begin{Description}
Estimation algorithm for generalized-GoM model with potentially locally dependent data
\end{Description}
%
\begin{Usage}
\begin{verbatim}
gGoM(
  R,
  K,
  pol = T,
  dist = NULL,
  large = T,
  prune = T,
  r = 10,
  q = 0.4,
  e = 0.2
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{R}] data matrix.

\item[\code{K}] integer. The number of extreme latent profiles. \code{K} should be at least 2.

\item[\code{pol}] logical; if true, assume GoM model with polytomous response, and flattening is applied. Item parameter estimation \code{T\_hat} is also flattened.

\item[\code{dist}] character; One of \code{"Bern"}, \code{"Binom"}, and \code{"Pois"}. Specifies the data distribution.
\code{"Bern"} assumes the Bernoulli distribution.
\code{"Binom"} assumes the Binomial distribution.
\code{"Pois"} assumes the Poisson distribution.

\item[\code{large}] logical; if true, \code{K} needs to be at least 3 and use the large-scale SVD function \code{RSpectra::svds}.

\item[\code{prune}] logical; if true, the pruning step is performed.

\item[\code{r}] the number of neighbors to consider in pruning. Used only when \code{prune} is \code{TRUE}. Default value is 10.

\item[\code{q}] the cutoff for the upper quantile of row norms. Used only when \code{prune} is \code{TRUE}. Higher \code{q} leads to more points being pruned. Default value is 0.4.

\item[\code{e}] the cutoff for the upper quantile of average distance. Used only when \code{prune} is \code{TRUE}. Higher \code{e} leads to more points being pruned. Default value is 0.2.

\item[\code{lower}] the minimum value for item parameters. Default value is 0.

\item[\code{upper}] the minimum value for item parameters. Default value is 1.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
The function returns a list with the following components:
\begin{itemize}

\item{} \code{P\_hat} the estimated membership scores.
\item{} \code{T\_hat} the estimated item response parameters.
\item{} \code{R\_hat} the estimated response expectation.
\item{} \code{S\_hat} the estimated indices of pure subjects.
\item{} \code{t} computation time.

\end{itemize}

\end{Value}
%
\begin{References}
Chen, Ling, and Yuqi Gu. "A spectral method for identifiable grade of membership analysis with binary responses." Psychometrika (2024): 1-32.

Chen, Ling, Chengzhu Huang, and Yuqi Gu. "Generalized Grade-of-Membership Estimation for High-dimensional Locally Dependent Data." arXiv preprint arXiv:2412.19796 (2024).
\end{References}
\HeaderA{gomSVD}{gomSVD}{gomSVD}
%
\begin{Description}
Estimation algorithm for gGoM model with the left singular matrix.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
gomSVD(U, V, d, prune = T, r = 10, q = 0.4, e = 0.2)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{U}] the pruned left singular matrix from data SVD.

\item[\code{V}] the right singular matrix from data SVD.

\item[\code{d}] the vector containing the singular values.

\item[\code{prune}] logical; if true, the pruning step is performed.

\item[\code{r}] the number of neighbors to consider in pruning. Used only when \code{prune} is \code{TRUE}. Default value is 10.

\item[\code{q}] the cutoff for the upper quantile of row norms. Used only when \code{prune} is \code{TRUE}. Higher \code{q} leads to more points being pruned. Default value is 0.4.

\item[\code{e}] the cutoff for the upper quantile of average distance. Used only when \code{prune} is \code{TRUE}. Higher \code{e} leads to more points being pruned. Default value is 0.2.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
The function returns a list with the following components:
\begin{itemize}

\item{} \code{P\_hat} the estimated membership scores.
\item{} \code{T\_hat} the estimated item response parameters (not truncated).
\item{} \code{R\_hat} the estimated response expectation (not truncated).
\item{} \code{S\_hat} the estimated indices of pure subjects.
\item{} \code{t} computation time.

\end{itemize}

\end{Value}
\HeaderA{heteroPCA}{heteroPCA}{heteroPCA}
%
\begin{Description}
This function implements the HeteroPCA algorithm
\end{Description}
%
\begin{Usage}
\begin{verbatim}
heteroPCA(R, K, T0)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{R}] Numeric matrix. The matrix to perform HeteroPCA.

\item[\code{K}] Positive integer. The number of top eigenvectors to be extracted.

\item[\code{T0}] Positive integer. The number of iterations.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Numeric matrix \code{U\_hat}
\end{Value}
%
\begin{References}
Zhang, Anru R., T. Tony Cai, and Yihong Wu. "Heteroskedastic PCA: Algorithm, optimality, and applications." The Annals of Statistics 50.1 (2022): 53-80.
\end{References}
\HeaderA{perm}{perm}{perm}
%
\begin{Description}
This function performs permutation
\end{Description}
%
\begin{Usage}
\begin{verbatim}
perm(x, p)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] Numeric vector. Vector of labels with integer values 1, ..., K

\item[\code{p}] Numeric vector. An integer permutation vector.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Permuted vector \code{x\_perm}
\end{Value}
\HeaderA{pruning}{pruning}{pruning}
%
\begin{Description}
Locate noisy points in the data simplex.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
pruning(mat, r = 10, q = 0.4, e = 0.2)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mat}] a numeric matrix to be pruned.

\item[\code{r}] the number of neighbors to consider. Default value is 10.

\item[\code{q}] the cutoff for the upper quantile of row norms. Higher `q` leads to more points being pruned. Default value is 0.4.

\item[\code{e}] the cutoff for the upper quantile of average distance. Higher `e` leads to more points being pruned. Default value is 0.2.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
\begin{description}

\item[\code{indices}    the index vector of the rows to be pruned from the left singular matrix.] 
\end{description}

\end{Value}
%
\begin{References}
Mao, X., Sarkar, P., \& Chakrabarti, D. (2021). Estimating mixed memberships with sharp eigenvector deviations. Journal of the American Statistical Association, 116(536), 1928-1940.
\end{References}
\HeaderA{rescale\_T}{rescale\_T}{rescale.Rul.T}
%
\begin{Description}
Re-scale the item parameter estimation \code{T\_hat} for polytomous GoM
\end{Description}
%
\begin{Usage}
\begin{verbatim}
rescale_T(T_mat, Cs)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{T\_mat}] Numeric matrix. Item parameter matrix.

\item[\code{Cs}] Integer vector. The number of categories for each item
\end{ldescription}
\end{Arguments}
%
\begin{Value}
\begin{description}

\item[\code{T\_mat}    flattened item parameter matrix estimation.] 
\end{description}

\end{Value}
\HeaderA{spa}{spa}{spa}
%
\begin{Description}
A sequential projection algorithm (SPA) to find the pure subjects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
spa(mat)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mat}] the (pruned) left singular matrix to conduct SPA on.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
\begin{description}

\item[\code{S\_hat}    a vector of the pure subject indices.] 
\end{description}

\end{Value}
%
\begin{References}
Gillis, N. and Vavasis, S. A. (2013). Fast and robust recursive algorithms for separable nonnegative matrix factorization. IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(4):698â€“714.
\end{References}
\HeaderA{SpecLatent}{Spectral Methods for Latent Variable Models}{SpecLatent}
\aliasA{SpecLatent-package}{SpecLatent}{SpecLatent.Rdash.package}
%
\begin{Description}
This package contains spectral methods for latent variable models, including the generalized-GoM model and degree-heterogeneous latent class model.
\end{Description}
%
\begin{Details}
Spectral Methods for Latent Variable Models

A package that contains spectral methods for latent variable models.
\end{Details}
%
\begin{Section}{Authors}
Ling Chen (\email{lc3521@columbia.edu}), Yuqi Gu, Zhongyuan Lyu, Chengzhu Huang, Seunghyun Lee
\end{Section}
%
\begin{Section}{Data Example}


The package includes a sample dataset, `anes`, from the American National Election Studies (ANES) 2022 pilot study
\end{Section}
%
\begin{Author}
Ling Chen (\email{lc3521@columbia.edu}), Yuqi Gu, Zhongyuan Lyu, Chengzhu Huang, Seunghyun Lee
\end{Author}
%
\begin{SeeAlso}
Useful links:
\begin{itemize}

\item{} Report bugs at \url{https://github.com/lscientific/SpecLatent/issues}

\end{itemize}


\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

# Load the dataset
data(anes)

# Inspect the first few rows and columns of the dataset
anes[1:6, 1:6]

# Estimation of the polytomous GoM model parameters
res <- gGoM(anes[, 2:146], K=3, pol=T, dist=NULL, large=T, prune=T, r=10, q=0.4, e=0.2)

# ternary plot
library(ggtern)
# ternary
data_tern <- as.data.frame(res$P_hat)
data_tern$party <- as.factor(anes$party)
ggtern(data=data_tern, aes(V2, V1, V3)) + 
  geom_point(size=0.7, aes(color=party), alpha=1) + 
  xlab("Conservative") + ylab("Indifferent") + zlab("Liberal") + 
  theme(axis.title=element_text(size=8.5), 
        legend.title= element_text(size=9), 
        legend.text=element_text(size=9), 
        legend.key.size=unit(0.6, 'cm'), 
        legend.position = "bottom", 
        tern.axis.title.L = element_text(hjust = 0.2, vjust = 0.5),
        tern.axis.title.R = element_text(hjust = 0.8, vjust = 0.5),
        legend.box.margin = margin(-35, 0, 0, 0), 
        plot.margin = margin(-15, -15, 0, -30)) +
  scale_color_manual(values=c('#377EC2', "#7FBFBB", '#e26b57'))


\end{ExampleCode}
\end{Examples}
\printindex{}
\end{document}
